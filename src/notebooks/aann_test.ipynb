{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# INFO411/911 Project Autoassociative Memory MLP Test"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== # IMPORTS # ===== #\n",
        "import scipy\n",
        "import numpy as np\n",
        "import sklearn as sk\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "outputs": [],
      "execution_count": 46,
      "metadata": {
        "collapsed": false,
        "inputHidden": false,
        "outputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== # IMPORTING DATASET # ===== #\n",
        "# iris = datasets.load_iris()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Printing some sample data from the iris dataset\")\n",
        "for training_sample in list(zip(iris.data,iris.target))[:5]:\n",
        "    print(training_sample)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Printing some sample data from the iris dataset\n",
            "(array([5.1, 3.5, 1.4, 0.2]), 0)\n",
            "(array([4.9, 3. , 1.4, 0.2]), 0)\n",
            "(array([4.7, 3.2, 1.3, 0.2]), 0)\n",
            "(array([4.6, 3.1, 1.5, 0.2]), 0)\n",
            "(array([5. , 3.6, 1.4, 0.2]), 0)\n"
          ]
        }
      ],
      "execution_count": 16,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save the features and class\n",
        " \n",
        "X = iris.data   \t# split iris dataset into X input and Y class labels\n",
        "Y = iris.target     # class[X] is output corresponding to features[X]"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training (70%) and testing (30%)\n",
        "# Note that the shuffle parameter has been used in splitting.\n",
        " \n",
        "print(\"Splitting the data into testing and training samples\")\n",
        "ratio_train, ratio_test = 0.7 , 0.3\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "  X, Y, \n",
        "  train_size=ratio_train,test_size=ratio_test, \n",
        "  shuffle=True\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splitting the data into testing and training samples\n"
          ]
        }
      ],
      "execution_count": 19,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data preprocessing: Before training the network we must scale the feature data\n",
        "print(\"Data preprocessing\")\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data preprocessing\n"
          ]
        }
      ],
      "execution_count": 21,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X Train Shape: {}\".format(X_train_scaled.shape))\n",
        "\n",
        "unique, counts = np.unique(Y, return_counts=True)\n",
        "print(\"Class Distribution: \\n{}\".format(dict(zip(unique, counts))))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X Train Shape: (105, 4)\n",
            "Class Distribution: \n",
            "{0: 50, 1: 50, 2: 50}\n"
          ]
        }
      ],
      "execution_count": 51,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The MLPClassifier and MLPRegressor are sklearn implementations of NNs\n",
        "iterations = 1000           # define the iterations for training over the dataset\n",
        "hidden_layers = (5,)      # define the layers/depth of the NN\n",
        "alpha = 1e-05               # define the learning rate\n",
        "activation = 'relu'         # define the activation function in {‘identity’, ‘logistic’, ‘tanh’, ‘relu’}\n",
        "solver = 'sgd'              # define the solver for weight optimization in {‘lbfgs’, ‘sgd’, ‘adam’}\n",
        "\n",
        "\n",
        "print(\"Creating a neural network with {} layers and {} iterations\"\n",
        "      .format(len(hidden_layers), iterations))\n",
        "\n",
        "mlp = MLPClassifier(\n",
        "  alpha              = alpha,\n",
        "  hidden_layer_sizes = (hidden_layers),\n",
        "  max_iter           = iterations,\n",
        "  activation         = activation,\n",
        "  solver             = solver\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating a neural network with 1 layers and 1000 iterations\n"
          ]
        }
      ],
      "execution_count": 105,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# an object which represents the neural network\n",
        "# Remember to use the pre-processed data and not original values for fit()\n",
        " \n",
        "mlp.fit(X_train_scaled, Y_train)  # fit features over NN"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 106,
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
              "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "       hidden_layer_sizes=(5,), learning_rate='constant',\n",
              "       learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
              "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "       random_state=None, shuffle=True, solver='sgd', tol=0.0001,\n",
              "       validation_fraction=0.1, verbose=False, warm_start=False)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 106,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the test data over the network to see the predicted outcomes.\n",
        "predictions = mlp.predict(X_test_scaled)  # predict over test data"
      ],
      "outputs": [],
      "execution_count": 107,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluation: Mean Accuracy Train Set\")\n",
        "print(\"{:.5f}\".format(mlp.score(X_train_scaled, Y_train)))\n",
        "\n",
        "print(\"Evaluation: Mean Accuracy Test Set\")\n",
        "print(\"{:.5f}\".format(mlp.score(X_test_scaled, Y_test)))\n",
        "\n",
        "## evaluation metrics and analysing the accuracy/output.\n",
        "print(\"Evaluation: Confusion Matrix\")\n",
        "print(confusion_matrix(Y_test, predictions))  \n",
        "# all non-diagonal elements are 0 if you get 100% accuracy\n",
        "\n",
        "print(\"Evaluation report:\")\n",
        "print(classification_report(Y_test, predictions)) \n",
        "#f1-score/accuracy"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation: Mean Accuracy Train Set\n",
            "0.96190\n",
            "Evaluation: Mean Accuracy Test Set\n",
            "0.95556\n",
            "Evaluation: Confusion Matrix\n",
            "[[16  0  0]\n",
            " [ 0 10  0]\n",
            " [ 0  2 17]]\n",
            "Evaluation report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        16\n",
            "           1       0.83      1.00      0.91        10\n",
            "           2       1.00      0.89      0.94        19\n",
            "\n",
            "   micro avg       0.96      0.96      0.96        45\n",
            "   macro avg       0.94      0.96      0.95        45\n",
            "weighted avg       0.96      0.96      0.96        45\n",
            "\n"
          ]
        }
      ],
      "execution_count": 115,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}